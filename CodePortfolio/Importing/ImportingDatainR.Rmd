---
title: "Importing Data in R"
author: "Rose Mariyappan"
date: "April 21, 2019"
output: 
  html_document: 
    toc: true
    number_sections: true
---

# Importing Data

This document contains useful code snippets related to data importing in *R* programming language. Reference include:

* [DataCamp](https://www.datacamp.com/home)

## Importing data from flat files with utils
The `utils` package is automatically loaded in your R session on startup, can import CSV files with `read.csv()` function. 

Use `read.csv()` to import "swimming_pools.csv" as a data frame with the name `pools`
```{r eval = FALSE}
pools <- read.csv("swimming_pools.csv")
```
Print the structure of `pools` using `str()`
```{r eval = FALSE}
str(pools)
```
set `stringsAsFactors` to *TRUE* to convert strings in the flat file to factors
```{r eval = FALSE}
pools <- read.csv("swimming_pools.csv", stringsAsFactors = FALSE)
```

## readr & data.table
Aside from `.csv files`, there are also the .txt files which are basically text files. You can import these functions with `read.delim()`. By default, it sets the `sep` argument to "\t" (fields in a record are delimited by tabs) and the `header` argument to *TRUE* (the first row contains the field names). 

Import the data in "hotdogs.txt" with `read.delim()`. Call the resulting data frame hotdogs. The variable names are not on the first line, so set the `header` argumet to *FALSE*. Alternatively, set their column names.
```{r eval = FALSE}
hotdogs <- read.delim("hotdogs.txt", header = FALSE)
hotdogs <- read.delim("hotdogs.txt", header = FALSE, col.names = c("type", "calories", "sodium"))
```
Print summary statistics about all variables in the data frame using `summary()`.
```{r eval = FALSE}
summary(hotdogs)
```
If you're dealing with more exotic flat file formats, you'll want to use `read.table()`. Unlike `read.csv()` and `read.delim()`, the `header` argument defaults to *FALSE* and the `sep` argument is "" by default.
Set path to the hotdogs.txt file: path
```{r eval = FALSE}
path <- file.path("data", "hotdogs.txt")
```
Import the hotdogs.txt file setting the column names: hotdogs
```{r eval = FALSE}
hotdogs <- read.table(path, 
                      sep = "\t", 
                      col.names = c("type", "calories", "sodium"))
```
Specify the column types or column classes of the resulting data frame. You can do this by setting the colClasses argument to a vector of strings representing classes:
Edit the colClasses argument to import the data correctly: hotdogs2
```{r eval = FALSE}
hotdogs2 <- read.delim("hotdogs.txt", header = FALSE, 
                       col.names = c("type", "calories", "sodium"),
                       colClasses = c("factor", "NULL", "numeric"))
```
Call `head()` on hotdogs to print the first 6 observations in the data frame.
```{r eval = FALSE}
head(hotdogs)
```
Select the hot dog with the least calories: lily. 
It uses the function which.min(), that returns the index the smallest value in a vector.
```{r eval = FALSE}
lily <- hotdogs[which.min(hotdogs$calories), ]
```
Select the observation with the most sodium: tom. Use which.max().
```{r eval = FALSE}
tom <- hotdogs[which.max(hotdogs$sodium), ]
```
CSV files can be imported with read_csv(). It's a wrapper function around read_delim() that handles all the details for you. For example, it will assume that the first row contains the column names.
Load the `readr` package
```{r eval = FALSE}
library(readr)
```
Import potatoes.csv with read_csv(): potatoes
```{r eval = FALSE}
potatoes <- read_csv("potatoes.csv")
```
Use read_tsv() to easily read in TSV files. TSV is short for tab-separated values. Set the path, column names.
```{r eval = FALSE}
path <- file.path("~", "potatoes.txt")
properties <- c("area", "temp", "size", "storage", "method",
                "texture", "flavor", "moistness")
potatoes <- read_tsv(path, col_names = properties)
```
Manually set the types with a string, where each character denotes the class of the column: character, double, integer and logical. _ skips the column as a whole.
```{r eval = FALSE}
potatoes_char <- read_tsv("potatoes.txt", col_types = "cccccccc", col_names = properties)
```
Another way of setting the types of the imported columns is using collectors. Collector functions can be passed in a list() to the col_types argument of read_ functions to tell them how to interpret values in a column.
The collectors you will need to import the data
```{r eval = FALSE}
fac <- col_factor(levels = c("Beef", "Meat", "Poultry"))
int <- col_integer()
```
Specify the col_types argument to import the data correctly: hotdogs_factor
```{r eval = FALSE}
hotdogs_factor <- read_tsv("hotdogs.txt",
                           col_names = c("type", "calories", "sodium"),
                           col_types = list(fac, int, int))
```
Just as read.table() was the main utils function, read_delim() is the main readr function. `delim` is the character that separates the values in the data file.
Import potatoes.txt using read_delim(): potatoes. 
```{r eval = FALSE}
potatoes <- read_delim("potatoes.txt", delim="\t", col_names = properties)
```
skip specifies the number of lines you're ignoring in the flat file before actually starting to import data.
n_max specifies the number of lines you're actually importing. 
Skip 6 lines and import 5 observations below.
```{r eval = FALSE}
potatoes_fragment <- read_tsv("potatoes.txt", skip = 6, n_max = 5, col_names = properties)
```
`fread()` is a function that does the same job as `read.table()`
load the data.table package to use `fread()`
```{r eval = FALSE}
library(data.table)
```
Import potatoes.csv with fread(): potatoes
```{r eval = FALSE}
potatoes <- fread("potatoes.csv")
```
Use drop and select, to drop or select variables of interest.
```{r eval = FALSE}
fread("path/to/file.txt", drop = 2:4)
fread("path/to/file.txt", select = c(1, 5))
fread("path/to/file.txt", drop = c("b", "c", "d"))
fread("path/to/file.txt", select = c("a", "e"))
```

## Importing Excel data

Which sheets are available in the workbook. You can use the excel_sheets() function for this.

Load the readxl package
```{r eval = FALSE}
library(readxl)
```
Print the names of all worksheets
```{r eval = FALSE}
excel_sheets("urbanpop.xlsx")
```
Import those sheets into R. You can do this with the read_excel() function specifying sheet name or number.
```{r eval = FALSE}
data <- read_excel("data.xlsx", sheet = "my_sheet")
data <- read_excel("data.xlsx", sheet = 2)
```
Read all Excel sheets with lapply(). 
```{r eval = FALSE}
my_workbook <- lapply(excel_sheets("data.xlsx"),
                      read_excel,
                      path = "data.xlsx")
```
Import the first Excel sheet of urbanpop_nonames.xlsx specifying col_names
```{r eval = FALSE}
cols <- c("country", paste0("year_", 1960:1966))
pop_b <- read_excel("urbanpop_nonames.xlsx", col_names = cols)
```
With skip, you can tell R to ignore a specified number of rows inside the Excel sheets you're trying to pull data from. 
Import the second sheet of urbanpop.xlsx, skipping the first 21 rows
```{r eval = FALSE}
urbanpop_sel <- read_excel("urbanpop.xlsx", sheet = 2, skip = 21, col_names = FALSE)
```
Import .xls files using the gdata package. Import the second sheet of urbanpop.xls. Can also specify skip rows.
```{r eval = FALSE}
library(gdata)
urban_pop <- read.xls("urbanpop.xls", sheet = "1967-1974")
urban_pop <- read.xls("urbanpop.xls", sheet = 2,
                      skip = 50, header = FALSE, stringsAsFactors = FALSE, col.names = columns)
```
Import data from all three sheets in urbanpop.xls. Merge sheets using the cbind() call.
```{r eval = FALSE}
path <- "urbanpop.xls"
urban_sheet1 <- read.xls(path, sheet = 1, stringsAsFactors = FALSE)
urban_sheet2 <- read.xls(path, sheet = 2, stringsAsFactors = FALSE)
urban_sheet3 <- read.xls(path, sheet = 3, stringsAsFactors = FALSE)
urban <- cbind(urban_sheet1, urban_sheet2[-1], urban_sheet3[-1])
```

## Reproducible Excel work with XLConnect
When working with XLConnect, the first step will be to load a workbook in your R session with loadWorkbook(); this function will build a "bridge" between your Excel file and your R session.

Load the XLConnect package
```{r eval = FALSE}
library(XLConnect)
```
Build connection to urbanpop.xlsx: my_book
```{r eval = FALSE}
my_book <- loadWorkbook("urbanpop.xlsx")
```
List the sheets in my_book
```{r eval = FALSE}
getSheets(my_book)
```
Import the second sheet in my_book
```{r eval = FALSE}
readWorksheet(my_book, sheet = 2)
```
Import all sheets in my_book using lapply
```{r eval = FALSE}
my_book <- loadWorkbook("urbanpop.xlsx")
sheets <- getSheets(my_book)
all <- lapply(sheets, readWorksheet, object = my_book)
str(all)
```
Import columns 3, 4, and 5 from second sheet in my_book
```{r eval = FALSE}
urbanpop_sel <- readWorksheet(my_book, sheet = 2, startCol = 3, endCol = 5)
```
Import first column from second sheet in my_book
```{r eval = FALSE}
countries <- readWorksheet(my_book, sheet = 2, startCol = 1, endCol = 1) 
```
Use cbind() urbanpop_sel and countries together
```{r eval = FALSE}
selection <- cbind(countries, urbanpop_sel)
```
Use createSheet(), to create a new sheet in my_book. Build connection to urbanpop.xlsx & add worksheet.
```{r eval = FALSE}
my_book <- loadWorkbook("urbanpop.xlsx")
createSheet(my_book, name = "data_summary")
```
Create data frame: summ before writing to worksheet data_summary
```{r eval = FALSE}
sheets <- getSheets(my_book)[1:3]
dims <- sapply(sheets, function(x) dim(readWorksheet(my_book, sheet = x)), USE.NAMES = FALSE)
summ <- data.frame(sheets = sheets,
                   nrows = dims[1, ],
                   ncols = dims[2, ])
```
Add data in summ to "data_summary" sheet
```{r eval = FALSE}
writeWorksheet(my_book, summ, sheet = "data_summary")
```
Save workbook as summary.xlsx
```{r eval = FALSE}
saveWorkbook(my_book, file = "summary.xlsx")
```
Rename "data_summary" sheet to "summary" and save workbook
```{r eval = FALSE}
renameSheet(my_book, "data_summary", "summary")
```
Remove the summary sheet and save workbook
```{r eval = FALSE}
removeSheet(my_book, sheet = "summary")
```